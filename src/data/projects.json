{
    "1": {
        "name": "Cloud Brokerage Platform",
        "sections": [
        {
            "header": "Stakeholders",
            "text": [{
                "p": "Executives, dev managers, devOps professionals"
            }]
        },
        {
            "header": "Why",
            "text": [{
                "p": "With businesses moving to the cloud cost overruns are a becoming more common. Executives and managers need better insight into the cloud spend before large surprise bills. DevOps team members need to be able to quickly tend to resources that are creating issues from a cost perspective."
            }]
        },
        {
            "header": "What",
            "text": [{
                "p": "The team set out to deliver a platform that would allow organizations to determine which cloud provider would be serve their purpose as well as helping them understand the potential costs at any time with the help of data analytics."
            }]
        },
        {
            "header": "How",
            "text": [{
                "p": "There was preliminary research that suggested there was an opportunity for our platform to be useful to a large audience. To kickoff the project, I facilitated a design thinking workshop to align stakeholders. This workshop allowed everyone (engineering, executives, product management, etc.) to express concerns and desires. The workshop also allowed us to agree on key pain points to address.",
                "images": [
                    {
                        "caption": "Exercise in design thinking workshop I facilitated.",
                        "url": "/images/cloud-brokerage/workshop_01.png"
                    },
                    {
                        "caption": "Exercise in design thinking workshop I facilitated.",
                        "url": "/images/cloud-brokerage/workshop_02.png"
                    },
                    {
                        "caption": "Exercise in design thinking workshop I facilitated.",
                        "url": "/images/cloud-brokerage/workshop_03.png"
                    }
                    ]},
            {
                "p": "After the completion of the workshop, I lead the effort to create the information architecture and lead a team of visual designers to design the UI for the product. The design began to take form after a couple of sketching sessions that allowed us to address issues without being focused on the aesthetics.",
                "images": [{
                    "caption": "Image from product sketching session",
                    "url": "/images/cloud-brokerage/process_01.png"
                },
                {
                    "caption": "Image from product sketching session",
                    "url": "/images/cloud-brokerage/process_02.png"
                },
                {
                    "caption": "Image from product sketching session",
                    "url": "/images/cloud-brokerage/process_03.png"
                }]
            },
            {
                "p": "Once we felt issues were addressed appropriately I direct the team to start applying visual. With my direction, the visual design team iterated over visual treatments until we all aligned.",
                "images": [{
                    "caption": "Low fidelity UI sketch",
                    "url": "/images/cloud-brokerage/sketch_01.png"
                },
                {
                    "caption": "Low fidelity UI sketch",
                    "url": "/images/cloud-brokerage/sketch_02.png"
                },
                {
                    "caption": "Low fidelity UI sketch",
                    "url": "/images/cloud-brokerage/sketch_03.png"
                },
                {
                    "caption": "High fidelity UI screen",
                    "url": "/images/cloud-brokerage/product_01.png"
                },
                {
                    "caption": "High fidelity UI screen",
                    "url": "/images/cloud-brokerage/product_02.png"
                },
                {
                    "caption": "High fidelity UI screen",
                    "url": "/images/cloud-brokerage/product_03.png"
                }]
            }]
            
        },
        {
            "header": "Takeaways",
            "text": [{
                "p": "The product allowed management to quickly get insight into the month's cloud spend. Should anomalies be identified, devOps would easily be able to identify problem resources and rectify the issue. The product allowed companies to capture money"
            }]
        },
        {
            "header": "Tools & Roles",
            "text": [{
                "p": "Role: UX Design, Information Architect, Design/Project Manager"
            }]
        }]
    },
    "2": {
        "name": "Data Pipeline",
        "sub": "Machine learning and sports",
        "sections": [{
            "header": "Stakeholders",
            "text": [{
                "p":"Sports bettors"
            }]
        },{
            "header": "Opportunity",
            "text": [{
                "p":"As an avid sports fan, I wanted to take my knowledge of predictive analytics and love of sports to build a data pipeline that would predict the total over/under for the second half of basketball and football games.",
                "images": []
            }]
        },
        {
            "header": "Process",
            "text": [{
                "p": "During the football season I manually captured betting data and game stats in a spreadsheet. I used the data collected to train my models. As the dataset grew, I got what I considered decent results from my models.",
                "images": [{
                    "caption": "Jupyter notebook was used for the initial manual entry.",
                    "url": "/images/data-pipeline/notebook.png"
                },
                {
                    "caption": "Predictions were placed in spreadsheet to be analyzed.",
                    "url": "/images/data-pipeline/spreadsheet.png"
                }]
            },
            {
                "p": "I decided to build out the pipeline to support basketball. Due to the vast number of basketball games my manual approach was not going to work. An automated pipeline was needed in order for it to be effective. As a way to avoid the costly service fees for the needed data, I researched web scraping. With this knowledge in hand I was able to collect the data I needed from various sites and store the data in a spreadsheet. I was now able to automate the capturing of the data and predictive modeling. I simply had my application look for games that were at the half and run predictions for the 2nd half.",
                "images" : [{
                    "caption": "Betting lines were scrapped from Draftkings.com",
                    "url": "/images/data-pipeline/02.png"
                },
                {
                    "caption": "Stats and scores were scrapped from ESPN.com",
                    "url": "/images/data-pipeline/01.png"
                },
                {
                    "caption": "Stats and scores were scrapped from ESPN.com",
                    "url": "/images/data-pipeline/03.png"
                }],
                "videos": [{
                    "caption": "Web scrapping and analysis workflow update automated.",
                    "url": "https://thompsonjamesquillan-portfolio.s3.us-east-2.amazonaws.com/pipeline.mp4"
                }]
            }]
        },
        {
            "header": "Solution",
            "text": [{
                "p": "I was given access to a live sports betting API. I wrote a Python application that would update the betting lines up until tip off. The application would check the progress of games and once a game was in halftime the application would get the updated stats and betting lines. The updated stats and betting lines were used to determine if an over or under bet should be made for the second half. The script would be started before the tip of the first game of the day and would run until the last game finished. A Google Sheet was updated with the results.",
                "images": [
                {
                    "caption": "Final prediction and result spreadsheet.",
                    "url": "/images/data-pipeline/04.png"
                },
                {
                    "caption": "Pregame betting predictions",
                    "url": "/images/data-pipeline/05.png"
                }]
            }]
        },{
            "header": "Tools & Roles",
            "text": [{
                "p": "Tools: Python, GoogleSheets,\nRole: Backend Development, Data Analyst"
            }]
        }]
    },
    "3": {
        "name": "Photography Utility",
        "sections": [
        {
            "header": "Stakeholders",
            "text": [{
                "p": "Studio photographers, My photographer friend was doing a product photoshoot. The photos were going to be used on a website but he had no idea how they would look. As he was shooting tethered to the computer the idea came to mind to take the photos as they come in and drop them into a web template, allowing him to see how the photos would look online in real-time."
            }]
        },
        {
            "header": "Opportunity",
            "text": [{
                "p": "I was speaking with a photographer who mentioned he was doing a product shoot for a clothing website. It came to my attention that he would simply be shooting the images without an idea of how the images would look in a web context. I wanted to help him and other product photographers have a better idea of how their images would be presented in their final web format in real-time. The idea being that the photographer need to know nothing about web development, this way they can focus on what they know, photography.",
                "images": [
                    {
                        "caption": "Tethered studio setup.",
                        "url": "/images/photography-utility/studio_01.png"
                    },
                    {
                        "caption": "Tethered studio setup.",
                        "url": "/images/photography-utility/studio_02.png"
                    }
                ]
            }]
        },
        {
            "header": "Deliverable",
            "text": [{
                "p": "I built a product website that consisted of a product list page and a product details page. Each page had some styling applied and this styling could be adjusted by the photographer or their team to fit their needs.",
                "images": [
                    {
                        "caption": "Sketch of product list page.",
                        "url": "/images/photography-utility/sketch_01.png"
                    },
                    {
                        "caption": "Sketch of product page.",
                        "url": "/images/photography-utility/sketch_02.png"
                    }
                ]
            },
            {
                "p": "I had a good understanding of the tethering process. What I didn’t not understand was how to work with filesystems programmatically. After my research into programmatically manipulating filesystems, I set out to build a simply utility that would watch a folder and copy any added photographs to the web directory. Once in the web directory the website would automatically reload displaying the new photo in the web template.",
                "videos": [{
                    "caption": "Simulation of photograph entering computer and responsive website updating automatically.",
                    "url": "https://thompsonjamesquillan-portfolio.s3.us-east-2.amazonaws.com/workflow.mp4"
                }]
            },
            {
                "p": "Once complete, I reached out to my friend to have him test everything out. I took his feedback to fine tune the utility documentation as well as the web template. He integrated the utility into his workflow and was able to fine tune photographs based on what he saw on the web demo",
                "images": [{
                    "caption":"Screenshot of utility in use.",
                    "url": "/images/photography-utility/inuse_01.png"
                },
                {
                    "caption":"Screenshot of utility in use.",
                    "url": "/images/photography-utility/inuse_02.png"
                }]
            }]
        },
        {
            "header": "Takeaways",
            "text": [{
                "p": "Once deployed I noticed that seemingly duplicate images would be presented in the template. It would be nice to allow a photographer to tag images and only those images tagged would show up giving a better idea of how website as a whole would look."}]
        },
        {
            "header": "Tools & Roles",
            "text": [{
                "p": "Tools: NodeJS, ReactJS \nRole: UX Design, Front and Backend Development"}]
        }]
    },
    "4": {
        "name": "Auto AI Utility",
        "sections": [{
            "header": "Stakeholders",
            "text": [{
                "p": "Front-end developers"
            }]
        },{
            "header": "Opportunity",
            "text": [{
                "p": "While there was a call to add more AI to IBM products there was very little AI in prototypes. The AI/ML learning curve is steep. I realized a process was needed to allow a UXE to quickly include a ML model into a prototype without extensive knowledge of model creation."
            }]
        },
        {
            "header": "Solution",
            "text": [{
                "p":"I developed a tool that would all a UXE to submit structured data and receive a predictive model in return. The UXE could then make API calls to the model to have actual predictions included in their prototypes instead of dummy data.",
                "images": [{
                    "caption": "UI of model creation script.",
                    "url": "/images/ai-utility/01.png"
                },
                {
                    "caption": "UI of model being used. 'Class' column is prediction column.",
                    "url": "/images/ai-utility/02.png"
                }]
            }]
        },
        {
            "header": "Tools & Roles",
            "text": "Tools: Python, ReactJS, Carbon \nRole: UX Design, Front and Backend Development",
            "images": []
        }]
    },
    "5": {
        "name": "SVG Animation",
        "sections": [{
            "header": "Tools & Roles",
            "text": [{
                "p": "Tools: ReactJS \nRole: Frontend Development"
            }]
        },{
            "header": "Problem",
            "text": [{
                "p": "Merging multiple pattern sites into one, there was a desire to highlight the number of patterns being used across the organization. Instead of using a flat chart, there was a desire to use an animated SVG."
            }]            
        },
        {
            "header": "Solution",
            "text": [{
                "p": "I was charged with implementing the animated SVG. Not knowing much about animated SVGs I collaborated with another team member who had a key piece of knowledge. Once I had that key piece of knowledge I was able to implement the animated SVG. Once implemented I began to figure out ways that would optimize the experience. I worked with the designer to understand how the exports were working and how we could exploit that to get our desired results. The animation has now been optimized",
                "videos": [{
                    "caption": "Animated SVG running on internal website.",
                    "url": "https://thompsonjamesquillan-portfolio.s3.us-east-2.amazonaws.com/svg.mp4"
                }]
            }]
        }]
    },
    "6": {
        "name": "Watson Assistant",
        "sections": [{
            "header": "Tools & Roles",
            "text": [{
                "p":"Tools: VueJS, \nRole: Frontend Development"
            }]
        },{
            "header": "Problem",
            "text": [{
                "p": "At the time, Watson Assistant 'out of the box' had no user interface. A customer would have to deploy resources to apply a user interface."
            }]
        },
        {
            "header": "Solution",
            "text": [{
                "p": "A generic user interface was applied to Watson Assistant, allowing a customer to focus on training the models and not the user interface. I developed a prototype to demonstrate the new chat window interface.",
                "videos": [{
                    "caption": "Simulation of user interacting with coded prototype of Watson Assistant",
                    "url": "https://thompsonjamesquillan-portfolio.s3.us-east-2.amazonaws.com/widget.mp4"
                }]
            }]
        }]
    }
}